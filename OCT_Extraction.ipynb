{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+YbTnVCz1877iMmR9l+GJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinliu23/DME-project/blob/main/OCT_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LMRmwDRSsH"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih-yIn-WON_C",
        "outputId": "5574713d-2482-414a-89c6-c57b8bfa63f8"
      },
      "source": [
        "# Authorize access to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeG7uVwRRhKm"
      },
      "source": [
        "def load_data(dir):\n",
        "    img_paths = []\n",
        "\n",
        "    for root, dirs, files in os.walk(dir):\n",
        "        for filename in files:\n",
        "            abs_path = os.path.abspath(os.path.join(root, filename))\n",
        "            img_paths.append(abs_path)\n",
        "\n",
        "    return img_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryOT3n-1XNd3"
      },
      "source": [
        "source_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/images_20K'\n",
        "\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/Abnormal OCT Scans.csv\")\n",
        "dme_file_list1 = df1.iloc[:, 0].tolist()\n",
        "# for i in range(len(dme_file_list1)):\n",
        "#   dme_file_list1[i] = dme_file_list1[i] + r'.jpg'\n",
        "# append the first file from the csv into the list, because pandas skips it\n",
        "dme_file_list1.insert(0, '609040_839547_9737192')\n",
        "\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/Abnormal OCT Scans 2.csv\")\n",
        "dme_file_list2 = df2.iloc[:, 0].tolist()\n",
        "for i in range(len(dme_file_list2)):\n",
        "  if r'.jpg' in dme_file_list2[i]: # standardize all filenames to not include .jpg\n",
        "    dme_file_list2[i] = dme_file_list2[i].replace(\".jpg\", \"\")\n",
        "# append the first file from the csv into the list, because pandas skips it\n",
        "dme_file_list2.insert(0, '100334_282444_1895586_NA')\n",
        "\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/Abnormal OCT Scans - Missing Images.csv\")\n",
        "dme_file_list3 = df3.iloc[:, 0].tolist()\n",
        "for i in range(len(dme_file_list3)):\n",
        "  if r'.jpg' in dme_file_list3[i]:\n",
        "    dme_file_list3[i] = dme_file_list3[i].replace(\".jpg\", \"\")\n",
        "# append the first file from the csv into the list, because pandas skips it\n",
        "dme_file_list3.insert(0, '609040_839547_9737192')\n",
        "\n",
        "# prevents duplicates\n",
        "dme_file_list = list(set(dme_file_list1 + dme_file_list2 + dme_file_list3))\n",
        "\n",
        "print(len(dme_file_list1))\n",
        "print(len(dme_file_list2))\n",
        "print(len(dme_file_list3))\n",
        "print(len(dme_file_list))\n",
        "print(dme_file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftYz9SJMwqzt"
      },
      "source": [
        "source_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/images_20K'\n",
        "\n",
        "all_img_paths = load_data(source_dir)\n",
        "print('# img paths:', len(all_img_paths))\n",
        "print(all_img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mofldkFu0zNe"
      },
      "source": [
        "source_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/Abnormal'\n",
        "\n",
        "ab_img_paths = load_data(source_dir)\n",
        "print('# img paths:', len(ab_img_paths))\n",
        "print(ab_img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDnoEVwod3_E"
      },
      "source": [
        "shortened_all_img_paths = []\n",
        "\n",
        "for i, img_path in enumerate(all_img_paths):\n",
        "    path_after_dir = r'/'.join(Path(img_path).parts[8:])\n",
        "    # path_after_dir = os.path.splitext(path_after_dir)[0]\n",
        "    shortened_all_img_paths.append(path_after_dir.replace('.jpg', ''))\n",
        "\n",
        "print(len(shortened_all_img_paths))\n",
        "print(shortened_all_img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICu4LsGA1775"
      },
      "source": [
        "shortened_ab_img_paths = []\n",
        "\n",
        "for i, img_path in enumerate(ab_img_paths):\n",
        "    path_after_dir = r'/'.join(Path(img_path).parts[8:])\n",
        "    # path_after_dir = os.path.splitext(path_after_dir)[0]\n",
        "    path_after_dir = path_after_dir.replace(' - Copy.jpg', '')\n",
        "    path_after_dir = path_after_dir.replace('.jpg', '')\n",
        "    shortened_ab_img_paths.append(path_after_dir)\n",
        "\n",
        "print(len(shortened_ab_img_paths))\n",
        "print(shortened_ab_img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4CdBPHl9mgp"
      },
      "source": [
        "dme_file_list = list(set(dme_file_list + shortened_ab_img_paths))\n",
        "print(len(dme_file_list))\n",
        "print(dme_file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usv4THSXfp4n"
      },
      "source": [
        "# normals = []\n",
        "# for i in shortened_all_img_paths:\n",
        "#   found = False\n",
        "#   for j in dme_file_list:\n",
        "#     if j in i: # some labels on spreadsheet weren't full filepath of file, so check as a substring (~string.contains)\n",
        "#       found = True\n",
        "#   if not found:\n",
        "#     normals.append(i)\n",
        "\n",
        "# print(normals)\n",
        "# print(len(normals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtOuNNZK4rQW"
      },
      "source": [
        "normals = []\n",
        "for i in shortened_all_img_paths:\n",
        "  found = False\n",
        "  for j in dme_file_list:\n",
        "    if j in i: # some labels on spreadsheet weren't full filepath of file, so check as a substring (~string.contains)\n",
        "      found = True\n",
        "  if not found:\n",
        "    normals.append(i)\n",
        "\n",
        "print(normals)\n",
        "print(len(normals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/images_20K'\n",
        "dest_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/Train/dme'\n",
        "\n",
        "count = 0\n",
        "for fp in dme_file_list:\n",
        "  if os.path.exists(os.path.join(source_dir, fp + r'.jpg')):\n",
        "    count += 1\n",
        "    shutil.copy(os.path.join(source_dir, fp + r'.jpg'), dest_dir)\n",
        "  # else:\n",
        "  #   print(fp) # prints missing image filenames\n",
        "\n",
        "print(count) # num of found image files"
      ],
      "metadata": {
        "id": "uSwjNY7cjssg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO0579Gnd_cN"
      },
      "source": [
        "dest_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/Train/normal'\n",
        "\n",
        "# we have ~650 DME OCT images, so we only need ~650 normal controls to create a balanced dataset\n",
        "for fp in random.sample(normals, 800): # random selection w/out duplicates\n",
        "  if os.path.exists(os.path.join(source_dir, fp + r'.jpg')):\n",
        "    # print(os.path.join(source_dir, fp))\n",
        "    shutil.copy(os.path.join(source_dir, fp + r'.jpg'), dest_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsrZM6A0rYbv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CJWuByYT2m7"
      },
      "source": [
        "def extract_oct_slices(file_paths, new_dir, plot=False):\n",
        "  BBOX_CONSTANT = 7 # pixel constant that removes the thin, outer white frame from bounding box segmentations\n",
        "  # SEGMENTATION_THRESHOLD = 220\n",
        "  DARKNESS_THRESHOLD = 50\n",
        "  MAX_BOXES = 15 # max num of rectanlges that will be detected when finding the boxes with largest area (the slices)\n",
        "\n",
        "  ROIs = []\n",
        "  ROI_images = []\n",
        "\n",
        "  for img_path in file_paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    img_copy = img.copy()\n",
        "    gray_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "    # threshold_value, binary_img = cv2.threshold(gray_img, SEGMENTATION_THRESHOLD, 255, 0)\n",
        "    threshold_value, binary_img = cv2.threshold(gray_img, 190, 255, cv2.THRESH_BINARY) # 150 instead of 190 also works well\n",
        "    # plt.imshow(binary_img)\n",
        "    # plt.show()\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    areas = [cv2.contourArea(contour) for contour in contours]\n",
        "\n",
        "    slices = 0\n",
        "    \n",
        "    for i in range(MAX_BOXES):\n",
        "      max_index = np.argmax(areas)\n",
        "      contour = contours[max_index]\n",
        "\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      xmin = x + BBOX_CONSTANT\n",
        "      xmax = x + w - BBOX_CONSTANT\n",
        "      ymin = y + BBOX_CONSTANT\n",
        "      ymax = y + h - BBOX_CONSTANT\n",
        "\n",
        "      ROI = img_copy[ymin:ymax, xmin:xmax]\n",
        "\n",
        "      pxl_mean = np.mean(ROI)\n",
        "      # print('pxl_mean:', pxl_mean)\n",
        "      if pxl_mean < DARKNESS_THRESHOLD: # only the OCT images have an overall pixel mean < 50 (mostly black)\n",
        "        slices += 1\n",
        "        ROIs.append(ROI)\n",
        "\n",
        "        # uncomment to draw green bboxes around the extracted slices --> saves to ROI_images\n",
        "        # cv2.rectangle(img_copy, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "\n",
        "        if plot:\n",
        "          plt.imshow(ROI)\n",
        "          plt.show()\n",
        "\n",
        "        path_after_dir = r'/'.join(Path(img_path).parts[8:])\n",
        "        # don't use the below line because some filenames have '.' before the filetype (ex: id_tag_#.Others.png)\n",
        "        # path_after_dir = path_after_dir[:str(path_after_dir).index('.')] + r'_slice_{}.png'.format(slices)\n",
        "        path_after_dir = str(path_after_dir)[:-4] + r'_slice_{}.png'.format(slices)\n",
        "        final_img_path = Path(os.path.join(new_dir, path_after_dir))\n",
        "        final_img_dir = final_img_path.parent\n",
        "        \n",
        "        # print('path_after_dir', path_after_dir)\n",
        "        # print('final_img_path', final_img_path)\n",
        "        # print('final_img_dir', final_img_dir)\n",
        "        # print('---------')\n",
        "\n",
        "        if os.path.isdir(str(final_img_dir)) == False:\n",
        "            os.makedirs(final_img_dir)\n",
        "            print('New directory made:', final_img_dir)\n",
        "\n",
        "        cv2.imwrite(str(final_img_path), ROI)\n",
        "\n",
        "      # remove the current contour (w/ greatest area) to prevent it from being detected on the next iteration\n",
        "      areas.remove(areas[max_index])\n",
        "      contours.pop(max_index)\n",
        "\n",
        "    ROI_images.append(img_copy)\n",
        "\n",
        "    if plot: # show whole image on last iteration\n",
        "      plt.imshow(img_copy)\n",
        "      plt.show()\n",
        "\n",
        "  return ROIs, ROI_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_qDcT8WRq6e"
      },
      "source": [
        "dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/OCT_Dataset'\n",
        "new_dir = r'/content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/OCT_Dataset_extractions'\n",
        "\n",
        "img_paths = load_data(dir)\n",
        "print('# img_paths:', len(img_paths))\n",
        "print(img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkFgQ5GD-pKJ",
        "outputId": "8871722d-12ff-4b84-e038-5c398972306f"
      },
      "source": [
        "ROIs, ROI_images = extract_oct_slices(img_paths, new_dir, plot=False)\n",
        "print('Total # Slices Extracted:', len(ROIs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New directory made: /content/drive/MyDrive/Colab Notebooks/Diabetic Retinopathy/OCT_Dataset_extracted/OCT_Dataset_extractions/Train/normal\n",
            "Total # Slices Extracted: 9539\n"
          ]
        }
      ]
    }
  ]
}